{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invisible-penguin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "removed-affect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_01</th>\n",
       "      <th>cat_02</th>\n",
       "      <th>cat_03</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>43</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>45%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>55%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>35%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>44</td>\n",
       "      <td>75%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>25%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cat_01  cat_02  cat_03 result\n",
       "0         1       0       0    10%\n",
       "1         1       1      10    20%\n",
       "2         1       2      10    30%\n",
       "3         1       3      28    50%\n",
       "4         1       4      28    70%\n",
       "5         1       5       1    90%\n",
       "6         1       6      37    60%\n",
       "7         1       7      37    60%\n",
       "8         1       8      19    30%\n",
       "9         1       9      19    20%\n",
       "10        1      10       0    10%\n",
       "11        2       0       0    10%\n",
       "12        2       1      11    20%\n",
       "13        2       2      11    30%\n",
       "14        2       3      29    50%\n",
       "15        2       4      29    70%\n",
       "16        2       5       2    90%\n",
       "17        2       6      38    60%\n",
       "18        2       7      38    70%\n",
       "19        2       8      20    65%\n",
       "20        2       9      20    55%\n",
       "21        2      10       0    10%\n",
       "22        3       0       0    10%\n",
       "23        3       1      12    20%\n",
       "24        3       2      12    30%\n",
       "25        3       3      30    50%\n",
       "26        3       4      30    70%\n",
       "27        3       5       3    90%\n",
       "28        3       6      39    40%\n",
       "29        3       7      39    30%\n",
       "30        3       8      21    15%\n",
       "31        3       9      21    20%\n",
       "32        3      10       0    10%\n",
       "33        4       0       0    10%\n",
       "34        4       1      13    20%\n",
       "35        4       2      13    30%\n",
       "36        4       3      31    50%\n",
       "37        4       4      31    70%\n",
       "38        4       5       4    90%\n",
       "39        4       6      40    75%\n",
       "40        4       7      40    65%\n",
       "41        4       8      22    30%\n",
       "42        4       9      22    25%\n",
       "43        4      10       0    10%\n",
       "44        5       0       0    10%\n",
       "45        5       1      14    20%\n",
       "46        5       2      14    30%\n",
       "47        5       3      32    50%\n",
       "48        5       4      32    70%\n",
       "49        5       5       5    60%\n",
       "50        5       6      41    40%\n",
       "51        5       7      41    35%\n",
       "52        5       8      23    25%\n",
       "53        5       9      23    25%\n",
       "54        5      10       0    10%\n",
       "55        6       0       0    10%\n",
       "56        6       1      15    20%\n",
       "57        6       2      15    30%\n",
       "58        6       3      33    50%\n",
       "59        6       4      33    70%\n",
       "60        6       5       6    60%\n",
       "61        6       6      42    45%\n",
       "62        6       7      42    40%\n",
       "63        6       8      24    35%\n",
       "64        6       9      24    25%\n",
       "65        6      10       0    10%\n",
       "66        7       0       0    10%\n",
       "67        7       1      16    20%\n",
       "68        7       2      16    30%\n",
       "69        7       3      34    50%\n",
       "70        7       4      34    70%\n",
       "71        7       5       7    80%\n",
       "72        7       6      43    50%\n",
       "73        7       7      43    45%\n",
       "74        7       8      25    40%\n",
       "75        7       9      25    35%\n",
       "76        7      10       0    10%\n",
       "77        8       0       0    10%\n",
       "78        8       1      17    20%\n",
       "79        8       2      17    30%\n",
       "80        8       3      35    50%\n",
       "81        8       4      35    70%\n",
       "82        8       5       8    85%\n",
       "83        8       6      44    75%\n",
       "84        8       7      44    70%\n",
       "85        8       8      26    65%\n",
       "86        8       9      26    40%\n",
       "87        8      10       0    10%\n",
       "88        9       0       0    10%\n",
       "89        9       1      18    20%\n",
       "90        9       2      18    30%\n",
       "91        9       3      36    50%\n",
       "92        9       4      36    70%\n",
       "93        9       5       9    90%\n",
       "94        9       6      45    75%\n",
       "95        9       7      45    60%\n",
       "96        9       8      27    55%\n",
       "97        9       9      27    35%\n",
       "98        9      10       0    10%\n",
       "99       10       0       0    10%\n",
       "100      10       1      10    20%\n",
       "101      10       2      10    30%\n",
       "102      10       3      28    50%\n",
       "103      10       4      28    70%\n",
       "104      10       5       1    90%\n",
       "105      10       6      37    60%\n",
       "106      10       7      37    60%\n",
       "107      10       8      19    30%\n",
       "108      10       9      19    20%\n",
       "109      10      10       0    10%\n",
       "110      11       0       0    10%\n",
       "111      11       1      11    20%\n",
       "112      18      10       0    10%\n",
       "113       1       9      19    20%\n",
       "114       1      10       0    10%\n",
       "115       2       0       0    10%\n",
       "116       2       1      11    20%\n",
       "117       2       2      11    30%\n",
       "118       2       3      29    50%\n",
       "119      11       9      20    55%\n",
       "120      11      10       0    10%\n",
       "121      12       0       0    10%\n",
       "122      12       1      12    20%\n",
       "123      12       2      12    30%\n",
       "124      12       3      30    50%\n",
       "125      12       4      30    70%\n",
       "126      12       5       3    90%\n",
       "127      12       6      39    40%\n",
       "128      12       7      39    30%\n",
       "129      12       8      21    15%\n",
       "130      12       9      21    20%\n",
       "131      12      10       0    10%\n",
       "132      13       0       0    10%\n",
       "133      13       1      13    20%\n",
       "134      13       2      13    30%\n",
       "135      13       3      31    50%\n",
       "136      13       4      31    70%\n",
       "137      13       5       4    90%\n",
       "138      13       6      40    75%\n",
       "139      13       7      40    65%\n",
       "140      13       8      22    30%\n",
       "141      13       9      22    25%\n",
       "142      13      10       0    10%\n",
       "143      14       0       0    10%\n",
       "144      14       1      14    20%\n",
       "145      14       2      14    30%\n",
       "146      14       3      32    50%\n",
       "147      14       4      32    70%\n",
       "148      14       5       5    60%\n",
       "149      14       6      41    40%\n",
       "150      14       7      41    35%\n",
       "151      14       8      23    25%\n",
       "152      14       9      23    25%\n",
       "153      14      10       0    10%\n",
       "154      15       0       0    10%\n",
       "155      15       1      15    20%\n",
       "156      15       2      15    30%\n",
       "157      15       3      33    50%\n",
       "158      15       4      33    70%\n",
       "159      15       5       6    60%\n",
       "160      15       6      42    45%\n",
       "161      15       7      42    40%\n",
       "162      15       8      24    35%\n",
       "163      15       9      24    25%\n",
       "164      15      10       0    10%\n",
       "165      16       0       0    10%\n",
       "166      16       1      16    20%\n",
       "167      16       2      16    30%\n",
       "168      16       3      34    50%\n",
       "169      16       4      34    70%\n",
       "170      16       5       7    80%\n",
       "171      16       6      43    50%\n",
       "172      16       7      43    45%\n",
       "173      16       8      25    40%\n",
       "174      16       9      25    35%\n",
       "175      16      10       0    10%\n",
       "176      17       0       0    10%\n",
       "177      17       1      17    20%\n",
       "178      17       2      17    30%\n",
       "179      17       3      35    50%\n",
       "180      17       4      35    70%\n",
       "181      17       5       8    85%\n",
       "182      17       6      44    75%\n",
       "183      17       7      44    70%\n",
       "184      17       8      26    65%\n",
       "185      17       9      26    40%\n",
       "186      17      10       0    10%\n",
       "187      18       0       0    10%\n",
       "188      18       1      18    20%\n",
       "189      18       2      18    30%\n",
       "190      18       3      36    50%\n",
       "191      18       4      36    70%\n",
       "192      18       5       9    90%\n",
       "193      18       6      45    75%\n",
       "194      18       7      45    60%\n",
       "195      18       8      27    55%\n",
       "196      18       9      27    35%\n",
       "197      18      10       0    10%\n",
       "198       1       9      19    20%\n",
       "199       1      10       0    10%\n",
       "200       2       0       0    10%\n",
       "201       2       1      11    20%\n",
       "202       2       2      11    30%\n",
       "203       2       3      29    50%\n",
       "204       2       4      29    70%\n",
       "205       2       5       2    90%\n",
       "206       2       6      38    60%\n",
       "207       2       7      38    70%\n",
       "208       2       8      20    65%\n",
       "209       2       9      20    55%\n",
       "210       2      10       0    10%\n",
       "211       3       0       0    10%\n",
       "212       3       1      12    20%\n",
       "213       3       2      12    30%\n",
       "214       3       3      30    50%\n",
       "215       3       4      30    70%\n",
       "216      14       1      14    20%\n",
       "217      14       2      14    30%\n",
       "218      14       3      32    50%\n",
       "219      14       4      32    70%\n",
       "220      14       5       5    60%\n",
       "221      14       6      41    40%\n",
       "222      14       7      41    35%\n",
       "223       5       5       5    60%\n",
       "224       5       6      41    40%\n",
       "225       5       7      41    35%\n",
       "226       5       8      23    25%\n",
       "227       5       9      23    25%\n",
       "228       5      10       0    10%\n",
       "229       6       0       0    10%\n",
       "230       6       1      15    20%\n",
       "231       6       2      15    30%\n",
       "232       6       3      33    50%\n",
       "233       6       4      33    70%\n",
       "234       6       5       6    60%\n",
       "235       6       6      42    45%\n",
       "236       6       7      42    40%\n",
       "237       6       8      24    35%\n",
       "238       6       9      24    25%\n",
       "239       6      10       0    10%\n",
       "240       7       0       0    10%\n",
       "241       7       1      16    20%\n",
       "242       7       2      16    30%\n",
       "243       5       1      14    20%\n",
       "244       5       2      14    30%\n",
       "245       5       3      32    50%\n",
       "246       5       4      32    70%\n",
       "247       5       5       5    60%\n",
       "248       5       6      41    40%\n",
       "249       5       7      41    35%\n",
       "250      18      10       0    10%\n",
       "251       1       9      19    20%\n",
       "252       1      10       0    10%\n",
       "253       2       0       0    10%\n",
       "254       2       1      11    20%\n",
       "255       2       2      11    30%\n",
       "256       2       3      29    50%\n",
       "257       9       4      36    70%\n",
       "258       9       5       9    90%\n",
       "259       9       6      45    75%\n",
       "260       9       7      45    60%\n",
       "261       9       8      27    55%\n",
       "262       9       9      27    35%\n",
       "263       9      10       0    10%\n",
       "264      10       0       0    10%\n",
       "265      10       1      10    20%\n",
       "266      10       2      10    30%\n",
       "267      10       3      28    50%\n",
       "268      10       4      28    70%\n",
       "269      10       5       1    90%\n",
       "270      10       6      37    60%\n",
       "271      10       7      37    60%\n",
       "272      10       8      19    30%\n",
       "273      10       9      19    20%\n",
       "274      10      10       0    10%\n",
       "275      11      10       0    10%\n",
       "276      12       0       0    10%\n",
       "277      12       1      12    20%\n",
       "278      12       2      12    30%\n",
       "279      12       3      30    50%\n",
       "280      12       4      30    70%\n",
       "281      12       5       3    90%\n",
       "282      12       6      39    40%\n",
       "283      12       7      39    30%\n",
       "284      12       8      21    15%\n",
       "285      16      10       0    10%\n",
       "286      17       0       0    10%\n",
       "287      17       1      17    20%\n",
       "288      17       2      17    30%\n",
       "289      17       3      35    50%\n",
       "290      17       4      35    70%\n",
       "291      17       5       8    85%\n",
       "292      17       6      44    75%\n",
       "293      17       7      44    70%\n",
       "294      17       8      26    65%\n",
       "295       4       7      40    65%\n",
       "296       4       8      22    30%\n",
       "297       4       9      22    25%\n",
       "298       4      10       0    10%\n",
       "299       5       0       0    10%\n",
       "300       5       1      14    20%\n",
       "301       5       2      14    30%\n",
       "302       5       3      32    50%\n",
       "303       5       4      32    70%\n",
       "304       5       5       5    60%\n",
       "305       5       6      41    40%\n",
       "306       5       7      41    35%\n",
       "307       5       8      23    25%\n",
       "308       5       9      23    25%\n",
       "309       5      10       0    10%\n",
       "310       6       0       0    10%\n",
       "311       6       1      15    20%\n",
       "312       6       2      15    30%\n",
       "313       6       3      33    50%\n",
       "314      14       6      41    40%\n",
       "315      14       7      41    35%\n",
       "316       5       5       5    60%\n",
       "317       5       6      41    40%\n",
       "318       5       7      41    35%\n",
       "319       5       8      23    25%\n",
       "320       5       9      23    25%\n",
       "321       5      10       0    10%\n",
       "322      16       7      43    45%\n",
       "323      16       8      25    40%\n",
       "324      16       9      25    35%\n",
       "325      16      10       0    10%\n",
       "326      17       0       0    10%\n",
       "327      17       1      17    20%\n",
       "328      17       2      17    30%\n",
       "329      17       3      35    50%\n",
       "330      17       4      35    70%\n",
       "331      17       5       8    85%\n",
       "332      17       6      44    75%\n",
       "333      17       7      44    70%\n",
       "334      17       8      26    65%\n",
       "335      17       9      26    40%\n",
       "336      17      10       0    10%\n",
       "337      18       0       0    10%\n",
       "338       1       9      19    20%\n",
       "339       1      10       0    10%\n",
       "340       2       0       0    10%\n",
       "341       2       1      11    20%\n",
       "342       2       2      11    30%\n",
       "343       2       3      29    50%\n",
       "344       2       4      29    70%\n",
       "345       2       5       2    90%\n",
       "346       2       6      38    60%\n",
       "347       2       7      38    70%\n",
       "348       2       8      20    65%\n",
       "349       2       9      20    55%\n",
       "350       2      10       0    10%\n",
       "351       3       0       0    10%\n",
       "352       5       6      41    40%\n",
       "353       5       7      41    35%\n",
       "354      18      10       0    10%\n",
       "355       1       9      19    20%\n",
       "356       1      10       0    10%\n",
       "357       2       0       0    10%\n",
       "358       2       1      11    20%\n",
       "359       2       2      11    30%\n",
       "360      14       7      41    35%\n",
       "361      14       8      23    25%\n",
       "362      14       9      23    25%\n",
       "363      14      10       0    10%\n",
       "364      15       0       0    10%\n",
       "365      15       1      15    20%\n",
       "366      15       2      15    30%\n",
       "367      15       3      33    50%\n",
       "368      15       4      33    70%\n",
       "369      15       5       6    60%\n",
       "370       6       1      15    20%\n",
       "371       6       2      15    30%\n",
       "372       6       3      33    50%\n",
       "373       6       4      33    70%\n",
       "374       6       5       6    60%\n",
       "375       6       6      42    45%\n",
       "376       6       7      42    40%\n",
       "377       6       8      24    35%\n",
       "378       6       9      24    25%\n",
       "379       6      10       0    10%\n",
       "380       7       0       0    10%\n",
       "381       7       1      16    20%\n",
       "382       7       2      16    30%\n",
       "383       7       3      34    50%\n",
       "384       7       4      34    70%\n",
       "385       7       5       7    80%\n",
       "386       7       6      43    50%\n",
       "387       7       7      43    45%\n",
       "388       7       8      25    40%\n",
       "389       7       9      25    35%\n",
       "390       7      10       0    10%\n",
       "391       8       0       0    10%\n",
       "392       8       1      17    20%\n",
       "393      12       8      21    15%\n",
       "394      12       9      21    20%\n",
       "395      12      10       0    10%\n",
       "396      13       0       0    10%\n",
       "397      13       1      13    20%\n",
       "398      13       2      13    30%\n",
       "399      13       3      31    50%\n",
       "400      13       4      31    70%\n",
       "401      13       5       4    90%\n",
       "402      13       6      40    75%\n",
       "403      13       7      40    65%\n",
       "404      13       8      22    30%\n",
       "405      13       9      22    25%\n",
       "406      13      10       0    10%\n",
       "407      14       0       0    10%\n",
       "408      14       1      14    20%\n",
       "409      14       2      14    30%\n",
       "410      14       3      32    50%\n",
       "411      14       4      32    70%\n",
       "412      14       5       5    60%\n",
       "413       6       2      15    30%\n",
       "414       6       3      33    50%\n",
       "415      14       6      41    40%\n",
       "416      14       7      41    35%\n",
       "417       5       5       5    60%\n",
       "418       5       6      41    40%\n",
       "419       5       7      41    35%\n",
       "420       5       8      23    25%\n",
       "421       5       9      23    25%\n",
       "422       5      10       0    10%\n",
       "423      16       7      43    45%\n",
       "424      16       8      25    40%\n",
       "425      16       9      25    35%\n",
       "426      16      10       0    10%\n",
       "427      17       0       0    10%\n",
       "428      17       1      17    20%\n",
       "429      17       2      17    30%\n",
       "430      17       3      35    50%\n",
       "431       4       5       4    90%\n",
       "432       4       6      40    75%\n",
       "433       4       7      40    65%\n",
       "434       4       8      22    30%\n",
       "435       4       9      22    25%\n",
       "436       4      10       0    10%\n",
       "437       5       0       0    10%\n",
       "438       5       1      14    20%\n",
       "439       5       2      14    30%\n",
       "440       5       3      32    50%\n",
       "441       5       4      32    70%\n",
       "442       5       5       5    60%\n",
       "443       5       6      41    40%\n",
       "444       5       7      41    35%\n",
       "445       5       8      23    25%\n",
       "446       5       9      23    25%\n",
       "447       5      10       0    10%\n",
       "448       6       0       0    10%\n",
       "449       6       1      15    20%\n",
       "450      14       2      14    30%\n",
       "451      14       3      32    50%\n",
       "452      14       4      32    70%\n",
       "453      14       5       5    60%\n",
       "454      14       6      41    40%\n",
       "455      14       7      41    35%\n",
       "456      14       8      23    25%\n",
       "457      14       9      23    25%\n",
       "458      14      10       0    10%\n",
       "459      15       0       0    10%\n",
       "460      15       1      15    20%\n",
       "461      15       2      15    30%\n",
       "462      15       3      33    50%\n",
       "463      15       4      33    70%\n",
       "464      15       5       6    60%\n",
       "465      15       3      33    50%\n",
       "466      15       4      33    70%\n",
       "467      15       5       6    60%\n",
       "468      15       6      42    45%\n",
       "469      15       7      42    40%\n",
       "470      15       8      24    35%\n",
       "471      15       9      24    25%\n",
       "472      15      10       0    10%\n",
       "473      16       0       0    10%\n",
       "474      16       1      16    20%\n",
       "475      16       2      16    30%\n",
       "476       9       8      27    55%\n",
       "477       9       9      27    35%\n",
       "478       9      10       0    10%\n",
       "479      10       0       0    10%\n",
       "480      10       1      10    20%\n",
       "481      10       2      10    30%\n",
       "482      10       3      28    50%\n",
       "483      10       4      28    70%\n",
       "484      10       5       1    90%\n",
       "485      10       6      37    60%\n",
       "486      10       7      37    60%\n",
       "487      10       8      19    30%\n",
       "488       7       9      25    35%\n",
       "489       7      10       0    10%\n",
       "490       8       0       0    10%\n",
       "491       8       1      17    20%\n",
       "492       8       2      17    30%\n",
       "493       8       3      35    50%\n",
       "494       8       4      35    70%\n",
       "495       8       5       8    85%\n",
       "496       8       6      44    75%\n",
       "497       8       7      44    70%\n",
       "498       8       8      26    65%\n",
       "499      14       9      23    25%"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/answer_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "needed-eleven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83289_row44_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83289\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_83289_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_83289_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_83289_row0_col0\" class=\"data row0 col0\" >session_id</td>\n",
       "      <td id=\"T_83289_row0_col1\" class=\"data row0 col1\" >8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_83289_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_83289_row1_col1\" class=\"data row1 col1\" >result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_83289_row2_col0\" class=\"data row2 col0\" >Target Type</td>\n",
       "      <td id=\"T_83289_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_83289_row3_col0\" class=\"data row3 col0\" >Label Encoded</td>\n",
       "      <td id=\"T_83289_row3_col1\" class=\"data row3 col1\" >10%: 0, 15%: 1, 20%: 2, 25%: 3, 30%: 4, 35%: 5, 40%: 6, 45%: 7, 50%: 8, 55%: 9, 60%: 10, 65%: 11, 70%: 12, 75%: 13, 80%: 14, 85%: 15, 90%: 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_83289_row4_col0\" class=\"data row4 col0\" >Original Data</td>\n",
       "      <td id=\"T_83289_row4_col1\" class=\"data row4 col1\" >(500, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_83289_row5_col0\" class=\"data row5 col0\" >Missing Values</td>\n",
       "      <td id=\"T_83289_row5_col1\" class=\"data row5 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_83289_row6_col0\" class=\"data row6 col0\" >Numeric Features</td>\n",
       "      <td id=\"T_83289_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_83289_row7_col0\" class=\"data row7 col0\" >Categorical Features</td>\n",
       "      <td id=\"T_83289_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_83289_row8_col0\" class=\"data row8 col0\" >Ordinal Features</td>\n",
       "      <td id=\"T_83289_row8_col1\" class=\"data row8 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_83289_row9_col0\" class=\"data row9 col0\" >High Cardinality Features</td>\n",
       "      <td id=\"T_83289_row9_col1\" class=\"data row9 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_83289_row10_col0\" class=\"data row10 col0\" >High Cardinality Method</td>\n",
       "      <td id=\"T_83289_row10_col1\" class=\"data row10 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_83289_row11_col0\" class=\"data row11 col0\" >Transformed Train Set</td>\n",
       "      <td id=\"T_83289_row11_col1\" class=\"data row11 col1\" >(349, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_83289_row12_col0\" class=\"data row12 col0\" >Transformed Test Set</td>\n",
       "      <td id=\"T_83289_row12_col1\" class=\"data row12 col1\" >(151, 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_83289_row13_col0\" class=\"data row13 col0\" >Shuffle Train-Test</td>\n",
       "      <td id=\"T_83289_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_83289_row14_col0\" class=\"data row14 col0\" >Stratify Train-Test</td>\n",
       "      <td id=\"T_83289_row14_col1\" class=\"data row14 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_83289_row15_col0\" class=\"data row15 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_83289_row15_col1\" class=\"data row15 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_83289_row16_col0\" class=\"data row16 col0\" >Fold Number</td>\n",
       "      <td id=\"T_83289_row16_col1\" class=\"data row16 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_83289_row17_col0\" class=\"data row17 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_83289_row17_col1\" class=\"data row17 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_83289_row18_col0\" class=\"data row18 col0\" >Use GPU</td>\n",
       "      <td id=\"T_83289_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_83289_row19_col0\" class=\"data row19 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_83289_row19_col1\" class=\"data row19 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_83289_row20_col0\" class=\"data row20 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_83289_row20_col1\" class=\"data row20 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_83289_row21_col0\" class=\"data row21 col0\" >USI</td>\n",
       "      <td id=\"T_83289_row21_col1\" class=\"data row21 col1\" >ba0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_83289_row22_col0\" class=\"data row22 col0\" >Imputation Type</td>\n",
       "      <td id=\"T_83289_row22_col1\" class=\"data row22 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_83289_row23_col0\" class=\"data row23 col0\" >Iterative Imputation Iteration</td>\n",
       "      <td id=\"T_83289_row23_col1\" class=\"data row23 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
       "      <td id=\"T_83289_row24_col0\" class=\"data row24 col0\" >Numeric Imputer</td>\n",
       "      <td id=\"T_83289_row24_col1\" class=\"data row24 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row25\" class=\"row_heading level0 row25\" >25</th>\n",
       "      <td id=\"T_83289_row25_col0\" class=\"data row25 col0\" >Iterative Imputation Numeric Model</td>\n",
       "      <td id=\"T_83289_row25_col1\" class=\"data row25 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row26\" class=\"row_heading level0 row26\" >26</th>\n",
       "      <td id=\"T_83289_row26_col0\" class=\"data row26 col0\" >Categorical Imputer</td>\n",
       "      <td id=\"T_83289_row26_col1\" class=\"data row26 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row27\" class=\"row_heading level0 row27\" >27</th>\n",
       "      <td id=\"T_83289_row27_col0\" class=\"data row27 col0\" >Iterative Imputation Categorical Model</td>\n",
       "      <td id=\"T_83289_row27_col1\" class=\"data row27 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row28\" class=\"row_heading level0 row28\" >28</th>\n",
       "      <td id=\"T_83289_row28_col0\" class=\"data row28 col0\" >Unknown Categoricals Handling</td>\n",
       "      <td id=\"T_83289_row28_col1\" class=\"data row28 col1\" >least_frequent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row29\" class=\"row_heading level0 row29\" >29</th>\n",
       "      <td id=\"T_83289_row29_col0\" class=\"data row29 col0\" >Normalize</td>\n",
       "      <td id=\"T_83289_row29_col1\" class=\"data row29 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row30\" class=\"row_heading level0 row30\" >30</th>\n",
       "      <td id=\"T_83289_row30_col0\" class=\"data row30 col0\" >Normalize Method</td>\n",
       "      <td id=\"T_83289_row30_col1\" class=\"data row30 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row31\" class=\"row_heading level0 row31\" >31</th>\n",
       "      <td id=\"T_83289_row31_col0\" class=\"data row31 col0\" >Transformation</td>\n",
       "      <td id=\"T_83289_row31_col1\" class=\"data row31 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row32\" class=\"row_heading level0 row32\" >32</th>\n",
       "      <td id=\"T_83289_row32_col0\" class=\"data row32 col0\" >Transformation Method</td>\n",
       "      <td id=\"T_83289_row32_col1\" class=\"data row32 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row33\" class=\"row_heading level0 row33\" >33</th>\n",
       "      <td id=\"T_83289_row33_col0\" class=\"data row33 col0\" >PCA</td>\n",
       "      <td id=\"T_83289_row33_col1\" class=\"data row33 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row34\" class=\"row_heading level0 row34\" >34</th>\n",
       "      <td id=\"T_83289_row34_col0\" class=\"data row34 col0\" >PCA Method</td>\n",
       "      <td id=\"T_83289_row34_col1\" class=\"data row34 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row35\" class=\"row_heading level0 row35\" >35</th>\n",
       "      <td id=\"T_83289_row35_col0\" class=\"data row35 col0\" >PCA Components</td>\n",
       "      <td id=\"T_83289_row35_col1\" class=\"data row35 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row36\" class=\"row_heading level0 row36\" >36</th>\n",
       "      <td id=\"T_83289_row36_col0\" class=\"data row36 col0\" >Ignore Low Variance</td>\n",
       "      <td id=\"T_83289_row36_col1\" class=\"data row36 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row37\" class=\"row_heading level0 row37\" >37</th>\n",
       "      <td id=\"T_83289_row37_col0\" class=\"data row37 col0\" >Combine Rare Levels</td>\n",
       "      <td id=\"T_83289_row37_col1\" class=\"data row37 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row38\" class=\"row_heading level0 row38\" >38</th>\n",
       "      <td id=\"T_83289_row38_col0\" class=\"data row38 col0\" >Rare Level Threshold</td>\n",
       "      <td id=\"T_83289_row38_col1\" class=\"data row38 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row39\" class=\"row_heading level0 row39\" >39</th>\n",
       "      <td id=\"T_83289_row39_col0\" class=\"data row39 col0\" >Numeric Binning</td>\n",
       "      <td id=\"T_83289_row39_col1\" class=\"data row39 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row40\" class=\"row_heading level0 row40\" >40</th>\n",
       "      <td id=\"T_83289_row40_col0\" class=\"data row40 col0\" >Remove Outliers</td>\n",
       "      <td id=\"T_83289_row40_col1\" class=\"data row40 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row41\" class=\"row_heading level0 row41\" >41</th>\n",
       "      <td id=\"T_83289_row41_col0\" class=\"data row41 col0\" >Outliers Threshold</td>\n",
       "      <td id=\"T_83289_row41_col1\" class=\"data row41 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row42\" class=\"row_heading level0 row42\" >42</th>\n",
       "      <td id=\"T_83289_row42_col0\" class=\"data row42 col0\" >Remove Multicollinearity</td>\n",
       "      <td id=\"T_83289_row42_col1\" class=\"data row42 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row43\" class=\"row_heading level0 row43\" >43</th>\n",
       "      <td id=\"T_83289_row43_col0\" class=\"data row43 col0\" >Multicollinearity Threshold</td>\n",
       "      <td id=\"T_83289_row43_col1\" class=\"data row43 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row44\" class=\"row_heading level0 row44\" >44</th>\n",
       "      <td id=\"T_83289_row44_col0\" class=\"data row44 col0\" >Remove Perfect Collinearity</td>\n",
       "      <td id=\"T_83289_row44_col1\" class=\"data row44 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row45\" class=\"row_heading level0 row45\" >45</th>\n",
       "      <td id=\"T_83289_row45_col0\" class=\"data row45 col0\" >Clustering</td>\n",
       "      <td id=\"T_83289_row45_col1\" class=\"data row45 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row46\" class=\"row_heading level0 row46\" >46</th>\n",
       "      <td id=\"T_83289_row46_col0\" class=\"data row46 col0\" >Clustering Iteration</td>\n",
       "      <td id=\"T_83289_row46_col1\" class=\"data row46 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row47\" class=\"row_heading level0 row47\" >47</th>\n",
       "      <td id=\"T_83289_row47_col0\" class=\"data row47 col0\" >Polynomial Features</td>\n",
       "      <td id=\"T_83289_row47_col1\" class=\"data row47 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row48\" class=\"row_heading level0 row48\" >48</th>\n",
       "      <td id=\"T_83289_row48_col0\" class=\"data row48 col0\" >Polynomial Degree</td>\n",
       "      <td id=\"T_83289_row48_col1\" class=\"data row48 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row49\" class=\"row_heading level0 row49\" >49</th>\n",
       "      <td id=\"T_83289_row49_col0\" class=\"data row49 col0\" >Trignometry Features</td>\n",
       "      <td id=\"T_83289_row49_col1\" class=\"data row49 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row50\" class=\"row_heading level0 row50\" >50</th>\n",
       "      <td id=\"T_83289_row50_col0\" class=\"data row50 col0\" >Polynomial Threshold</td>\n",
       "      <td id=\"T_83289_row50_col1\" class=\"data row50 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row51\" class=\"row_heading level0 row51\" >51</th>\n",
       "      <td id=\"T_83289_row51_col0\" class=\"data row51 col0\" >Group Features</td>\n",
       "      <td id=\"T_83289_row51_col1\" class=\"data row51 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row52\" class=\"row_heading level0 row52\" >52</th>\n",
       "      <td id=\"T_83289_row52_col0\" class=\"data row52 col0\" >Feature Selection</td>\n",
       "      <td id=\"T_83289_row52_col1\" class=\"data row52 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row53\" class=\"row_heading level0 row53\" >53</th>\n",
       "      <td id=\"T_83289_row53_col0\" class=\"data row53 col0\" >Feature Selection Method</td>\n",
       "      <td id=\"T_83289_row53_col1\" class=\"data row53 col1\" >classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row54\" class=\"row_heading level0 row54\" >54</th>\n",
       "      <td id=\"T_83289_row54_col0\" class=\"data row54 col0\" >Features Selection Threshold</td>\n",
       "      <td id=\"T_83289_row54_col1\" class=\"data row54 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row55\" class=\"row_heading level0 row55\" >55</th>\n",
       "      <td id=\"T_83289_row55_col0\" class=\"data row55 col0\" >Feature Interaction</td>\n",
       "      <td id=\"T_83289_row55_col1\" class=\"data row55 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row56\" class=\"row_heading level0 row56\" >56</th>\n",
       "      <td id=\"T_83289_row56_col0\" class=\"data row56 col0\" >Feature Ratio</td>\n",
       "      <td id=\"T_83289_row56_col1\" class=\"data row56 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row57\" class=\"row_heading level0 row57\" >57</th>\n",
       "      <td id=\"T_83289_row57_col0\" class=\"data row57 col0\" >Interaction Threshold</td>\n",
       "      <td id=\"T_83289_row57_col1\" class=\"data row57 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row58\" class=\"row_heading level0 row58\" >58</th>\n",
       "      <td id=\"T_83289_row58_col0\" class=\"data row58 col0\" >Fix Imbalance</td>\n",
       "      <td id=\"T_83289_row58_col1\" class=\"data row58 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83289_level0_row59\" class=\"row_heading level0 row59\" >59</th>\n",
       "      <td id=\"T_83289_row59_col0\" class=\"data row59 col0\" >Fix Imbalance Method</td>\n",
       "      <td id=\"T_83289_row59_col1\" class=\"data row59 col1\" >SMOTE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbe066dd6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cat_features = ['cat_01', 'cat_02','cat_03']\n",
    "experiment = setup(df, target='result', categorical_features=cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "reverse-brunswick",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a80d6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a80d6_row0_col0, #T_a80d6_row1_col0, #T_a80d6_row1_col1, #T_a80d6_row1_col3, #T_a80d6_row1_col4, #T_a80d6_row1_col5, #T_a80d6_row1_col6, #T_a80d6_row1_col7, #T_a80d6_row2_col0, #T_a80d6_row2_col1, #T_a80d6_row2_col3, #T_a80d6_row2_col4, #T_a80d6_row2_col5, #T_a80d6_row2_col6, #T_a80d6_row2_col7, #T_a80d6_row3_col0, #T_a80d6_row3_col1, #T_a80d6_row3_col3, #T_a80d6_row3_col4, #T_a80d6_row3_col5, #T_a80d6_row3_col6, #T_a80d6_row3_col7, #T_a80d6_row4_col0, #T_a80d6_row4_col1, #T_a80d6_row4_col3, #T_a80d6_row4_col4, #T_a80d6_row4_col5, #T_a80d6_row4_col6, #T_a80d6_row4_col7, #T_a80d6_row5_col0, #T_a80d6_row5_col1, #T_a80d6_row5_col3, #T_a80d6_row5_col4, #T_a80d6_row5_col5, #T_a80d6_row5_col6, #T_a80d6_row5_col7, #T_a80d6_row6_col0, #T_a80d6_row6_col1, #T_a80d6_row6_col3, #T_a80d6_row6_col4, #T_a80d6_row6_col5, #T_a80d6_row6_col6, #T_a80d6_row6_col7, #T_a80d6_row7_col0, #T_a80d6_row7_col1, #T_a80d6_row7_col3, #T_a80d6_row7_col4, #T_a80d6_row7_col5, #T_a80d6_row7_col6, #T_a80d6_row7_col7, #T_a80d6_row8_col0, #T_a80d6_row8_col1, #T_a80d6_row8_col3, #T_a80d6_row8_col4, #T_a80d6_row8_col5, #T_a80d6_row8_col6, #T_a80d6_row8_col7, #T_a80d6_row9_col0, #T_a80d6_row9_col1, #T_a80d6_row9_col3, #T_a80d6_row9_col4, #T_a80d6_row9_col5, #T_a80d6_row9_col6, #T_a80d6_row9_col7, #T_a80d6_row10_col0, #T_a80d6_row10_col1, #T_a80d6_row10_col3, #T_a80d6_row10_col4, #T_a80d6_row10_col5, #T_a80d6_row10_col6, #T_a80d6_row10_col7, #T_a80d6_row11_col0, #T_a80d6_row11_col1, #T_a80d6_row11_col3, #T_a80d6_row11_col4, #T_a80d6_row11_col5, #T_a80d6_row11_col6, #T_a80d6_row11_col7, #T_a80d6_row12_col0, #T_a80d6_row12_col1, #T_a80d6_row12_col3, #T_a80d6_row12_col4, #T_a80d6_row12_col5, #T_a80d6_row12_col6, #T_a80d6_row12_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_a80d6_row0_col1, #T_a80d6_row0_col2, #T_a80d6_row0_col3, #T_a80d6_row0_col4, #T_a80d6_row0_col5, #T_a80d6_row0_col6, #T_a80d6_row0_col7, #T_a80d6_row1_col2, #T_a80d6_row2_col2, #T_a80d6_row3_col2, #T_a80d6_row4_col2, #T_a80d6_row5_col2, #T_a80d6_row6_col2, #T_a80d6_row7_col2, #T_a80d6_row8_col2, #T_a80d6_row9_col2, #T_a80d6_row10_col2, #T_a80d6_row11_col2, #T_a80d6_row12_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_a80d6_row0_col8, #T_a80d6_row1_col8, #T_a80d6_row2_col8, #T_a80d6_row3_col8, #T_a80d6_row4_col8, #T_a80d6_row5_col8, #T_a80d6_row6_col8, #T_a80d6_row7_col8, #T_a80d6_row9_col8, #T_a80d6_row10_col8, #T_a80d6_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_a80d6_row8_col8, #T_a80d6_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a80d6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a80d6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_a80d6_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_a80d6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_a80d6_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_a80d6_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_a80d6_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_a80d6_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_a80d6_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_a80d6_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_a80d6_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_a80d6_row0_col1\" class=\"data row0 col1\" >0.9971</td>\n",
       "      <td id=\"T_a80d6_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row0_col3\" class=\"data row0 col3\" >0.9900</td>\n",
       "      <td id=\"T_a80d6_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_a80d6_row0_col5\" class=\"data row0 col5\" >0.9981</td>\n",
       "      <td id=\"T_a80d6_row0_col6\" class=\"data row0 col6\" >0.9968</td>\n",
       "      <td id=\"T_a80d6_row0_col7\" class=\"data row0 col7\" >0.9969</td>\n",
       "      <td id=\"T_a80d6_row0_col8\" class=\"data row0 col8\" >0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_a80d6_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_a80d6_row1_col1\" class=\"data row1 col1\" >0.9943</td>\n",
       "      <td id=\"T_a80d6_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row1_col3\" class=\"data row1 col3\" >0.9829</td>\n",
       "      <td id=\"T_a80d6_row1_col4\" class=\"data row1 col4\" >0.9952</td>\n",
       "      <td id=\"T_a80d6_row1_col5\" class=\"data row1 col5\" >0.9941</td>\n",
       "      <td id=\"T_a80d6_row1_col6\" class=\"data row1 col6\" >0.9936</td>\n",
       "      <td id=\"T_a80d6_row1_col7\" class=\"data row1 col7\" >0.9938</td>\n",
       "      <td id=\"T_a80d6_row1_col8\" class=\"data row1 col8\" >0.3540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_a80d6_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_a80d6_row2_col1\" class=\"data row2 col1\" >0.9885</td>\n",
       "      <td id=\"T_a80d6_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row2_col3\" class=\"data row2 col3\" >0.9807</td>\n",
       "      <td id=\"T_a80d6_row2_col4\" class=\"data row2 col4\" >0.9881</td>\n",
       "      <td id=\"T_a80d6_row2_col5\" class=\"data row2 col5\" >0.9866</td>\n",
       "      <td id=\"T_a80d6_row2_col6\" class=\"data row2 col6\" >0.9872</td>\n",
       "      <td id=\"T_a80d6_row2_col7\" class=\"data row2 col7\" >0.9876</td>\n",
       "      <td id=\"T_a80d6_row2_col8\" class=\"data row2 col8\" >0.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_a80d6_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_a80d6_row3_col1\" class=\"data row3 col1\" >0.9626</td>\n",
       "      <td id=\"T_a80d6_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row3_col3\" class=\"data row3 col3\" >0.9494</td>\n",
       "      <td id=\"T_a80d6_row3_col4\" class=\"data row3 col4\" >0.9656</td>\n",
       "      <td id=\"T_a80d6_row3_col5\" class=\"data row3 col5\" >0.9582</td>\n",
       "      <td id=\"T_a80d6_row3_col6\" class=\"data row3 col6\" >0.9585</td>\n",
       "      <td id=\"T_a80d6_row3_col7\" class=\"data row3 col7\" >0.9598</td>\n",
       "      <td id=\"T_a80d6_row3_col8\" class=\"data row3 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row4\" class=\"row_heading level0 row4\" >lda</th>\n",
       "      <td id=\"T_a80d6_row4_col0\" class=\"data row4 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_a80d6_row4_col1\" class=\"data row4 col1\" >0.9282</td>\n",
       "      <td id=\"T_a80d6_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row4_col3\" class=\"data row4 col3\" >0.9155</td>\n",
       "      <td id=\"T_a80d6_row4_col4\" class=\"data row4 col4\" >0.9564</td>\n",
       "      <td id=\"T_a80d6_row4_col5\" class=\"data row4 col5\" >0.9291</td>\n",
       "      <td id=\"T_a80d6_row4_col6\" class=\"data row4 col6\" >0.9203</td>\n",
       "      <td id=\"T_a80d6_row4_col7\" class=\"data row4 col7\" >0.9231</td>\n",
       "      <td id=\"T_a80d6_row4_col8\" class=\"data row4 col8\" >0.0090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row5\" class=\"row_heading level0 row5\" >svm</th>\n",
       "      <td id=\"T_a80d6_row5_col0\" class=\"data row5 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_a80d6_row5_col1\" class=\"data row5 col1\" >0.9139</td>\n",
       "      <td id=\"T_a80d6_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row5_col3\" class=\"data row5 col3\" >0.8613</td>\n",
       "      <td id=\"T_a80d6_row5_col4\" class=\"data row5 col4\" >0.9168</td>\n",
       "      <td id=\"T_a80d6_row5_col5\" class=\"data row5 col5\" >0.9067</td>\n",
       "      <td id=\"T_a80d6_row5_col6\" class=\"data row5 col6\" >0.9043</td>\n",
       "      <td id=\"T_a80d6_row5_col7\" class=\"data row5 col7\" >0.9069</td>\n",
       "      <td id=\"T_a80d6_row5_col8\" class=\"data row5 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_a80d6_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_a80d6_row6_col1\" class=\"data row6 col1\" >0.8996</td>\n",
       "      <td id=\"T_a80d6_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row6_col3\" class=\"data row6 col3\" >0.8446</td>\n",
       "      <td id=\"T_a80d6_row6_col4\" class=\"data row6 col4\" >0.8944</td>\n",
       "      <td id=\"T_a80d6_row6_col5\" class=\"data row6 col5\" >0.8868</td>\n",
       "      <td id=\"T_a80d6_row6_col6\" class=\"data row6 col6\" >0.8884</td>\n",
       "      <td id=\"T_a80d6_row6_col7\" class=\"data row6 col7\" >0.8911</td>\n",
       "      <td id=\"T_a80d6_row6_col8\" class=\"data row6 col8\" >0.5010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row7\" class=\"row_heading level0 row7\" >nb</th>\n",
       "      <td id=\"T_a80d6_row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_a80d6_row7_col1\" class=\"data row7 col1\" >0.8825</td>\n",
       "      <td id=\"T_a80d6_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row7_col3\" class=\"data row7 col3\" >0.8560</td>\n",
       "      <td id=\"T_a80d6_row7_col4\" class=\"data row7 col4\" >0.8960</td>\n",
       "      <td id=\"T_a80d6_row7_col5\" class=\"data row7 col5\" >0.8729</td>\n",
       "      <td id=\"T_a80d6_row7_col6\" class=\"data row7 col6\" >0.8697</td>\n",
       "      <td id=\"T_a80d6_row7_col7\" class=\"data row7 col7\" >0.8733</td>\n",
       "      <td id=\"T_a80d6_row7_col8\" class=\"data row7 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_a80d6_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_a80d6_row8_col1\" class=\"data row8 col1\" >0.8595</td>\n",
       "      <td id=\"T_a80d6_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row8_col3\" class=\"data row8 col3\" >0.8142</td>\n",
       "      <td id=\"T_a80d6_row8_col4\" class=\"data row8 col4\" >0.8633</td>\n",
       "      <td id=\"T_a80d6_row8_col5\" class=\"data row8 col5\" >0.8452</td>\n",
       "      <td id=\"T_a80d6_row8_col6\" class=\"data row8 col6\" >0.8444</td>\n",
       "      <td id=\"T_a80d6_row8_col7\" class=\"data row8 col7\" >0.8487</td>\n",
       "      <td id=\"T_a80d6_row8_col8\" class=\"data row8 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "      <td id=\"T_a80d6_row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_a80d6_row9_col1\" class=\"data row9 col1\" >0.8252</td>\n",
       "      <td id=\"T_a80d6_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row9_col3\" class=\"data row9 col3\" >0.7773</td>\n",
       "      <td id=\"T_a80d6_row9_col4\" class=\"data row9 col4\" >0.8373</td>\n",
       "      <td id=\"T_a80d6_row9_col5\" class=\"data row9 col5\" >0.8088</td>\n",
       "      <td id=\"T_a80d6_row9_col6\" class=\"data row9 col6\" >0.8059</td>\n",
       "      <td id=\"T_a80d6_row9_col7\" class=\"data row9 col7\" >0.8105</td>\n",
       "      <td id=\"T_a80d6_row9_col8\" class=\"data row9 col8\" >0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row10\" class=\"row_heading level0 row10\" >lightgbm</th>\n",
       "      <td id=\"T_a80d6_row10_col0\" class=\"data row10 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_a80d6_row10_col1\" class=\"data row10 col1\" >0.7706</td>\n",
       "      <td id=\"T_a80d6_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row10_col3\" class=\"data row10 col3\" >0.6481</td>\n",
       "      <td id=\"T_a80d6_row10_col4\" class=\"data row10 col4\" >0.7465</td>\n",
       "      <td id=\"T_a80d6_row10_col5\" class=\"data row10 col5\" >0.7396</td>\n",
       "      <td id=\"T_a80d6_row10_col6\" class=\"data row10 col6\" >0.7447</td>\n",
       "      <td id=\"T_a80d6_row10_col7\" class=\"data row10 col7\" >0.7516</td>\n",
       "      <td id=\"T_a80d6_row10_col8\" class=\"data row10 col8\" >0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_a80d6_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_a80d6_row11_col1\" class=\"data row11 col1\" >0.3353</td>\n",
       "      <td id=\"T_a80d6_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row11_col3\" class=\"data row11 col3\" >0.1857</td>\n",
       "      <td id=\"T_a80d6_row11_col4\" class=\"data row11 col4\" >0.2375</td>\n",
       "      <td id=\"T_a80d6_row11_col5\" class=\"data row11 col5\" >0.2501</td>\n",
       "      <td id=\"T_a80d6_row11_col6\" class=\"data row11 col6\" >0.2358</td>\n",
       "      <td id=\"T_a80d6_row11_col7\" class=\"data row11 col7\" >0.3644</td>\n",
       "      <td id=\"T_a80d6_row11_col8\" class=\"data row11 col8\" >0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a80d6_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_a80d6_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_a80d6_row12_col1\" class=\"data row12 col1\" >0.2006</td>\n",
       "      <td id=\"T_a80d6_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row12_col3\" class=\"data row12 col3\" >0.0686</td>\n",
       "      <td id=\"T_a80d6_row12_col4\" class=\"data row12 col4\" >0.0402</td>\n",
       "      <td id=\"T_a80d6_row12_col5\" class=\"data row12 col5\" >0.0670</td>\n",
       "      <td id=\"T_a80d6_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_a80d6_row12_col8\" class=\"data row12 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbe2249d790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f5ee6 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5ee6_row0_col0, #T_f5ee6_row1_col0, #T_f5ee6_row1_col1, #T_f5ee6_row1_col3, #T_f5ee6_row1_col4, #T_f5ee6_row1_col5, #T_f5ee6_row1_col6, #T_f5ee6_row1_col7, #T_f5ee6_row2_col0, #T_f5ee6_row2_col1, #T_f5ee6_row2_col3, #T_f5ee6_row2_col4, #T_f5ee6_row2_col5, #T_f5ee6_row2_col6, #T_f5ee6_row2_col7, #T_f5ee6_row3_col0, #T_f5ee6_row3_col1, #T_f5ee6_row3_col3, #T_f5ee6_row3_col4, #T_f5ee6_row3_col5, #T_f5ee6_row3_col6, #T_f5ee6_row3_col7, #T_f5ee6_row4_col0, #T_f5ee6_row4_col1, #T_f5ee6_row4_col3, #T_f5ee6_row4_col4, #T_f5ee6_row4_col5, #T_f5ee6_row4_col6, #T_f5ee6_row4_col7, #T_f5ee6_row5_col0, #T_f5ee6_row5_col1, #T_f5ee6_row5_col3, #T_f5ee6_row5_col4, #T_f5ee6_row5_col5, #T_f5ee6_row5_col6, #T_f5ee6_row5_col7, #T_f5ee6_row6_col0, #T_f5ee6_row6_col1, #T_f5ee6_row6_col3, #T_f5ee6_row6_col4, #T_f5ee6_row6_col5, #T_f5ee6_row6_col6, #T_f5ee6_row6_col7, #T_f5ee6_row7_col0, #T_f5ee6_row7_col1, #T_f5ee6_row7_col3, #T_f5ee6_row7_col4, #T_f5ee6_row7_col5, #T_f5ee6_row7_col6, #T_f5ee6_row7_col7, #T_f5ee6_row8_col0, #T_f5ee6_row8_col1, #T_f5ee6_row8_col3, #T_f5ee6_row8_col4, #T_f5ee6_row8_col5, #T_f5ee6_row8_col6, #T_f5ee6_row8_col7, #T_f5ee6_row9_col0, #T_f5ee6_row9_col1, #T_f5ee6_row9_col3, #T_f5ee6_row9_col4, #T_f5ee6_row9_col5, #T_f5ee6_row9_col6, #T_f5ee6_row9_col7, #T_f5ee6_row10_col0, #T_f5ee6_row10_col1, #T_f5ee6_row10_col3, #T_f5ee6_row10_col4, #T_f5ee6_row10_col5, #T_f5ee6_row10_col6, #T_f5ee6_row10_col7, #T_f5ee6_row11_col0, #T_f5ee6_row11_col1, #T_f5ee6_row11_col3, #T_f5ee6_row11_col4, #T_f5ee6_row11_col5, #T_f5ee6_row11_col6, #T_f5ee6_row11_col7, #T_f5ee6_row12_col0, #T_f5ee6_row12_col1, #T_f5ee6_row12_col3, #T_f5ee6_row12_col4, #T_f5ee6_row12_col5, #T_f5ee6_row12_col6, #T_f5ee6_row12_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f5ee6_row0_col1, #T_f5ee6_row0_col2, #T_f5ee6_row0_col3, #T_f5ee6_row0_col4, #T_f5ee6_row0_col5, #T_f5ee6_row0_col6, #T_f5ee6_row0_col7, #T_f5ee6_row1_col2, #T_f5ee6_row2_col2, #T_f5ee6_row3_col2, #T_f5ee6_row4_col2, #T_f5ee6_row5_col2, #T_f5ee6_row6_col2, #T_f5ee6_row7_col2, #T_f5ee6_row8_col2, #T_f5ee6_row9_col2, #T_f5ee6_row10_col2, #T_f5ee6_row11_col2, #T_f5ee6_row12_col2 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f5ee6_row0_col8, #T_f5ee6_row1_col8, #T_f5ee6_row2_col8, #T_f5ee6_row3_col8, #T_f5ee6_row4_col8, #T_f5ee6_row5_col8, #T_f5ee6_row6_col8, #T_f5ee6_row7_col8, #T_f5ee6_row8_col8, #T_f5ee6_row9_col8, #T_f5ee6_row10_col8, #T_f5ee6_row11_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_f5ee6_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f5ee6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f5ee6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f5ee6_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f5ee6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_f5ee6_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_f5ee6_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_f5ee6_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_f5ee6_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_f5ee6_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_f5ee6_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_f5ee6_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_f5ee6_row0_col1\" class=\"data row0 col1\" >0.9971</td>\n",
       "      <td id=\"T_f5ee6_row0_col2\" class=\"data row0 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row0_col3\" class=\"data row0 col3\" >0.9900</td>\n",
       "      <td id=\"T_f5ee6_row0_col4\" class=\"data row0 col4\" >1.0000</td>\n",
       "      <td id=\"T_f5ee6_row0_col5\" class=\"data row0 col5\" >0.9981</td>\n",
       "      <td id=\"T_f5ee6_row0_col6\" class=\"data row0 col6\" >0.9968</td>\n",
       "      <td id=\"T_f5ee6_row0_col7\" class=\"data row0 col7\" >0.9969</td>\n",
       "      <td id=\"T_f5ee6_row0_col8\" class=\"data row0 col8\" >0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_f5ee6_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_f5ee6_row1_col1\" class=\"data row1 col1\" >0.9943</td>\n",
       "      <td id=\"T_f5ee6_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row1_col3\" class=\"data row1 col3\" >0.9829</td>\n",
       "      <td id=\"T_f5ee6_row1_col4\" class=\"data row1 col4\" >0.9952</td>\n",
       "      <td id=\"T_f5ee6_row1_col5\" class=\"data row1 col5\" >0.9941</td>\n",
       "      <td id=\"T_f5ee6_row1_col6\" class=\"data row1 col6\" >0.9936</td>\n",
       "      <td id=\"T_f5ee6_row1_col7\" class=\"data row1 col7\" >0.9938</td>\n",
       "      <td id=\"T_f5ee6_row1_col8\" class=\"data row1 col8\" >0.4640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_f5ee6_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_f5ee6_row2_col1\" class=\"data row2 col1\" >0.9885</td>\n",
       "      <td id=\"T_f5ee6_row2_col2\" class=\"data row2 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row2_col3\" class=\"data row2 col3\" >0.9807</td>\n",
       "      <td id=\"T_f5ee6_row2_col4\" class=\"data row2 col4\" >0.9881</td>\n",
       "      <td id=\"T_f5ee6_row2_col5\" class=\"data row2 col5\" >0.9866</td>\n",
       "      <td id=\"T_f5ee6_row2_col6\" class=\"data row2 col6\" >0.9872</td>\n",
       "      <td id=\"T_f5ee6_row2_col7\" class=\"data row2 col7\" >0.9876</td>\n",
       "      <td id=\"T_f5ee6_row2_col8\" class=\"data row2 col8\" >0.0770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_f5ee6_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_f5ee6_row3_col1\" class=\"data row3 col1\" >0.9626</td>\n",
       "      <td id=\"T_f5ee6_row3_col2\" class=\"data row3 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row3_col3\" class=\"data row3 col3\" >0.9494</td>\n",
       "      <td id=\"T_f5ee6_row3_col4\" class=\"data row3 col4\" >0.9656</td>\n",
       "      <td id=\"T_f5ee6_row3_col5\" class=\"data row3 col5\" >0.9582</td>\n",
       "      <td id=\"T_f5ee6_row3_col6\" class=\"data row3 col6\" >0.9585</td>\n",
       "      <td id=\"T_f5ee6_row3_col7\" class=\"data row3 col7\" >0.9598</td>\n",
       "      <td id=\"T_f5ee6_row3_col8\" class=\"data row3 col8\" >0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row4\" class=\"row_heading level0 row4\" >lda</th>\n",
       "      <td id=\"T_f5ee6_row4_col0\" class=\"data row4 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_f5ee6_row4_col1\" class=\"data row4 col1\" >0.9282</td>\n",
       "      <td id=\"T_f5ee6_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row4_col3\" class=\"data row4 col3\" >0.9155</td>\n",
       "      <td id=\"T_f5ee6_row4_col4\" class=\"data row4 col4\" >0.9564</td>\n",
       "      <td id=\"T_f5ee6_row4_col5\" class=\"data row4 col5\" >0.9291</td>\n",
       "      <td id=\"T_f5ee6_row4_col6\" class=\"data row4 col6\" >0.9203</td>\n",
       "      <td id=\"T_f5ee6_row4_col7\" class=\"data row4 col7\" >0.9231</td>\n",
       "      <td id=\"T_f5ee6_row4_col8\" class=\"data row4 col8\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row5\" class=\"row_heading level0 row5\" >svm</th>\n",
       "      <td id=\"T_f5ee6_row5_col0\" class=\"data row5 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_f5ee6_row5_col1\" class=\"data row5 col1\" >0.9139</td>\n",
       "      <td id=\"T_f5ee6_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row5_col3\" class=\"data row5 col3\" >0.8613</td>\n",
       "      <td id=\"T_f5ee6_row5_col4\" class=\"data row5 col4\" >0.9168</td>\n",
       "      <td id=\"T_f5ee6_row5_col5\" class=\"data row5 col5\" >0.9067</td>\n",
       "      <td id=\"T_f5ee6_row5_col6\" class=\"data row5 col6\" >0.9043</td>\n",
       "      <td id=\"T_f5ee6_row5_col7\" class=\"data row5 col7\" >0.9069</td>\n",
       "      <td id=\"T_f5ee6_row5_col8\" class=\"data row5 col8\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row6\" class=\"row_heading level0 row6\" >lr</th>\n",
       "      <td id=\"T_f5ee6_row6_col0\" class=\"data row6 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_f5ee6_row6_col1\" class=\"data row6 col1\" >0.8996</td>\n",
       "      <td id=\"T_f5ee6_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row6_col3\" class=\"data row6 col3\" >0.8446</td>\n",
       "      <td id=\"T_f5ee6_row6_col4\" class=\"data row6 col4\" >0.8944</td>\n",
       "      <td id=\"T_f5ee6_row6_col5\" class=\"data row6 col5\" >0.8868</td>\n",
       "      <td id=\"T_f5ee6_row6_col6\" class=\"data row6 col6\" >0.8884</td>\n",
       "      <td id=\"T_f5ee6_row6_col7\" class=\"data row6 col7\" >0.8911</td>\n",
       "      <td id=\"T_f5ee6_row6_col8\" class=\"data row6 col8\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row7\" class=\"row_heading level0 row7\" >nb</th>\n",
       "      <td id=\"T_f5ee6_row7_col0\" class=\"data row7 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_f5ee6_row7_col1\" class=\"data row7 col1\" >0.8825</td>\n",
       "      <td id=\"T_f5ee6_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row7_col3\" class=\"data row7 col3\" >0.8560</td>\n",
       "      <td id=\"T_f5ee6_row7_col4\" class=\"data row7 col4\" >0.8960</td>\n",
       "      <td id=\"T_f5ee6_row7_col5\" class=\"data row7 col5\" >0.8729</td>\n",
       "      <td id=\"T_f5ee6_row7_col6\" class=\"data row7 col6\" >0.8697</td>\n",
       "      <td id=\"T_f5ee6_row7_col7\" class=\"data row7 col7\" >0.8733</td>\n",
       "      <td id=\"T_f5ee6_row7_col8\" class=\"data row7 col8\" >0.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row8\" class=\"row_heading level0 row8\" >ridge</th>\n",
       "      <td id=\"T_f5ee6_row8_col0\" class=\"data row8 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_f5ee6_row8_col1\" class=\"data row8 col1\" >0.8595</td>\n",
       "      <td id=\"T_f5ee6_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row8_col3\" class=\"data row8 col3\" >0.8142</td>\n",
       "      <td id=\"T_f5ee6_row8_col4\" class=\"data row8 col4\" >0.8633</td>\n",
       "      <td id=\"T_f5ee6_row8_col5\" class=\"data row8 col5\" >0.8452</td>\n",
       "      <td id=\"T_f5ee6_row8_col6\" class=\"data row8 col6\" >0.8444</td>\n",
       "      <td id=\"T_f5ee6_row8_col7\" class=\"data row8 col7\" >0.8487</td>\n",
       "      <td id=\"T_f5ee6_row8_col8\" class=\"data row8 col8\" >0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "      <td id=\"T_f5ee6_row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_f5ee6_row9_col1\" class=\"data row9 col1\" >0.8252</td>\n",
       "      <td id=\"T_f5ee6_row9_col2\" class=\"data row9 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row9_col3\" class=\"data row9 col3\" >0.7773</td>\n",
       "      <td id=\"T_f5ee6_row9_col4\" class=\"data row9 col4\" >0.8373</td>\n",
       "      <td id=\"T_f5ee6_row9_col5\" class=\"data row9 col5\" >0.8088</td>\n",
       "      <td id=\"T_f5ee6_row9_col6\" class=\"data row9 col6\" >0.8059</td>\n",
       "      <td id=\"T_f5ee6_row9_col7\" class=\"data row9 col7\" >0.8105</td>\n",
       "      <td id=\"T_f5ee6_row9_col8\" class=\"data row9 col8\" >0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row10\" class=\"row_heading level0 row10\" >lightgbm</th>\n",
       "      <td id=\"T_f5ee6_row10_col0\" class=\"data row10 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_f5ee6_row10_col1\" class=\"data row10 col1\" >0.7706</td>\n",
       "      <td id=\"T_f5ee6_row10_col2\" class=\"data row10 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row10_col3\" class=\"data row10 col3\" >0.6481</td>\n",
       "      <td id=\"T_f5ee6_row10_col4\" class=\"data row10 col4\" >0.7465</td>\n",
       "      <td id=\"T_f5ee6_row10_col5\" class=\"data row10 col5\" >0.7396</td>\n",
       "      <td id=\"T_f5ee6_row10_col6\" class=\"data row10 col6\" >0.7447</td>\n",
       "      <td id=\"T_f5ee6_row10_col7\" class=\"data row10 col7\" >0.7516</td>\n",
       "      <td id=\"T_f5ee6_row10_col8\" class=\"data row10 col8\" >0.0390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row11\" class=\"row_heading level0 row11\" >ada</th>\n",
       "      <td id=\"T_f5ee6_row11_col0\" class=\"data row11 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_f5ee6_row11_col1\" class=\"data row11 col1\" >0.3353</td>\n",
       "      <td id=\"T_f5ee6_row11_col2\" class=\"data row11 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row11_col3\" class=\"data row11 col3\" >0.1857</td>\n",
       "      <td id=\"T_f5ee6_row11_col4\" class=\"data row11 col4\" >0.2375</td>\n",
       "      <td id=\"T_f5ee6_row11_col5\" class=\"data row11 col5\" >0.2501</td>\n",
       "      <td id=\"T_f5ee6_row11_col6\" class=\"data row11 col6\" >0.2358</td>\n",
       "      <td id=\"T_f5ee6_row11_col7\" class=\"data row11 col7\" >0.3644</td>\n",
       "      <td id=\"T_f5ee6_row11_col8\" class=\"data row11 col8\" >0.0410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f5ee6_level0_row12\" class=\"row_heading level0 row12\" >dummy</th>\n",
       "      <td id=\"T_f5ee6_row12_col0\" class=\"data row12 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_f5ee6_row12_col1\" class=\"data row12 col1\" >0.2006</td>\n",
       "      <td id=\"T_f5ee6_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row12_col3\" class=\"data row12 col3\" >0.0686</td>\n",
       "      <td id=\"T_f5ee6_row12_col4\" class=\"data row12 col4\" >0.0402</td>\n",
       "      <td id=\"T_f5ee6_row12_col5\" class=\"data row12 col5\" >0.0670</td>\n",
       "      <td id=\"T_f5ee6_row12_col6\" class=\"data row12 col6\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row12_col7\" class=\"data row12 col7\" >0.0000</td>\n",
       "      <td id=\"T_f5ee6_row12_col8\" class=\"data row12 col8\" >0.0030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbe236af7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top3 = compare_models(n_select = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documentary-flooring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=['cat_01', 'cat_02',\n",
       "                                                             'cat_03'],\n",
       "                                       display_types=True, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=[], target='result',\n",
       "                                       time_features=[])),\n",
       "                 ('imputer',\n",
       "                  Simple_Imputer(categorical_strategy='not_available',\n",
       "                                 fill_value_categorical=None,\n",
       "                                 fill_value_nu...\n",
       "                  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                         class_weight=None, criterion='gini',\n",
       "                                         max_depth=None, max_features='auto',\n",
       "                                         max_leaf_nodes=None, max_samples=None,\n",
       "                                         min_impurity_decrease=0.0,\n",
       "                                         min_impurity_split=None,\n",
       "                                         min_samples_leaf=1, min_samples_split=2,\n",
       "                                         min_weight_fraction_leaf=0.0,\n",
       "                                         n_estimators=100, n_jobs=-1,\n",
       "                                         oob_score=False, random_state=8370,\n",
       "                                         verbose=0, warm_start=False)]],\n",
       "          verbose=False),\n",
       " 'answer_train_models/Random_Forest_Classifier.pkl')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to 0.000000. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/pycaret/internal/pipeline.py\", line 118, in fit\n",
      "    result = super().fit(X, y=y, **fit_kwargs)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/imblearn/pipeline.py\", line 281, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params)\n",
      "  File \"/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py\", line 708, in fit\n",
      "    raise ValueError('y has only 1 sample in class %s, covariance '\n",
      "ValueError: y has only 1 sample in class 14, covariance is ill defined.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute standard_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_coef_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: Attribute average_intercept_ was deprecated in version 0.23 and will be removed in 0.25.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:715: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:740: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:741: RuntimeWarning: overflow encountered in square\n",
      "  norm2.append(np.sum(X2 ** 2, axis=1))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:743: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/utils/deprecation.py:101: FutureWarning: The outputs_2d_ attribute is deprecated in version 0.22 and will be removed in version 0.24. It is equivalent to n_outputs_ > 1.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/roshanwithanage/opt/anaconda3/envs/game5/lib/python3.8/site-packages/sklearn/metrics/_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "save_model(top3[2], model_name='answer_train_models/Random_Forest_Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-manor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
